% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/estimate-functions.R
\name{estimateCounts}
\alias{estimateCounts}
\title{Estimate counts and model from one or more noisy datasets.}
\usage{
estimateCounts(model, y, exposure = NULL, dataModels, datasets,
  concordances = list(), filename = NULL, nBurnin = 1000,
  nSim = 1000, nChain = 4, nThin = 1, parallel = TRUE,
  nCore = NULL, outfile = NULL, nUpdateMax = 50, verbose = FALSE,
  useC = TRUE)
}
\arguments{
\item{model}{An object of class \code{\linkS4class{SpecModel}},
specifying the model to be fit.}

\item{y}{An object of class
\code{\link[dembase:DemographicArray-class]{Counts}} with the same
structure as the counts to be estimated.}

\item{exposure}{A \code{\link[dembase:DemographicArray-class]{Counts}}
object specifying exposure or sample size.}

\item{dataModels}{A list of objects of class
\code{\linkS4class{SpecModel}} describing the relationship between 
the datasets and counts.}

\item{datasets}{A named list of objects of class
\code{\link[dembase:DemographicArray-class]{Counts}}.}

\item{concordances}{A named list of
\code{\link[dembase:Concordance-class]{concordances}},
which are applied to \code{y} before it is supplied to
the corresponding data model.}

\item{filename}{The name of a file where output is collected.}

\item{nBurnin}{Number of iteration discarded before recording begins.}

\item{nSim}{Number of iterations carried out during recording.}

\item{nChain}{Number of independent chains to use.}

\item{nThin}{Thinning interval.}

\item{parallel}{Logical.  If \code{TRUE} (the default), parallel processing
is used.}

\item{nCore}{The number of cores to use, when \code{parallel}
is \code{TRUE}.  If no value supplied, defaults to \code{nChain}.}

\item{outfile}{Where to direct the ‘stdout’ and ‘stderr’ connection
output from the workers when parallel processing.  Passed to function
\code{[parallel]{makeCluster}}.}

\item{nUpdateMax}{Maximum number of iterations completed before releasing
memory.  If running out of memory, setting a lower value than the default
may help.}

\item{verbose}{Logical.  If \code{TRUE} (the default) a message is
printed at the end of the calculations.}

\item{useC}{Logical.  If \code{TRUE} (the default), the calculations
are done in C.  Setting \code{useC} to \code{FALSE} may be useful
for debugging.}
}
\description{
Infer the contents of a demographic array, and fit a model describing
the array, using one or more noisy datasets.
}
\details{
See the documentation for \code{\link{estimateModel}} for details on
model output and on MCMC settings.

\code{dataModels} is a list of specificiations for data models,
and \code{datasets} is a named list of datasets.  The response for each
data model must be the name of a dataset.  See below for examples.
}
\examples{
nat <- demdata::sim.admin.nat
health <- demdata::sim.admin.health
survey <- demdata::sim.admin.survey
nat <- Counts(nat, dimscales = c(year = "Points"))
health <- Counts(health, dimscales = c(year = "Points"))
survey <- Counts(survey)
y <- health + 10
model <- Model(y ~ Poisson(mean ~ age + sex + region,
                           useExpose = FALSE))
dataModels <- list(Model(nat ~ PoissonBinomial(prob = 0.98)),
                   Model(health ~ Poisson(mean ~ age)),
                   Model(survey ~ Binomial(mean ~ 1)))
datasets <- list(nat = nat, health = health, survey = survey)
filename <- tempfile()
## in a real example, nBurnin and nSim would be much larger
\dontrun{
estimateCounts(model = model,
               y = y,
               dataModels = dataModels,
               datasets = datasets,
               filename = filename,
               nBurnin = 50,
               nSim = 50,
               nThin = 2,
               nChain = 2,
               parallel = FALSE)
fetchSummary(filename)
}
}
\seealso{
\code{\link{estimateModel}}, \code{\link{estimateAccount}}
}
